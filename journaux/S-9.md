#  Séance 9

## 6 avril 2023
**ZHANG**: Suite à la séance d'hier, la structure des données à renvoyer se montre plus éclaircie pour nous. Je me vois obligé de remodifier notre script **extraire_deux.py** dans la branche **main** afin que le résultat *xml* devienne plus conforme à la plulart de ce à quoi le professeur s'attend. Après son exécution, voici la forme du fichier sorti:
```
<Corpus begin="2022-01-01" end="2023-01-01" categories="international;une">
<article date="2022-03-14">
<title>
Dans l’est de la RDC, les ADF, un ennemi insaisissable pour les populations et pour l’armée
</title>
<desc>
Après vingt-sept ans d’exactions, les motivations du groupe armé créé en Ouganda, rallié à l’Etat islamique en 2019, restent floues.
</desc>
</article>
```
Le prochain serait alors de travailler avec le module de stockage des données `dataclasses` permettant ainsi de générer un résultat au format *xml* aussi bien que *json*  , et ensuite de tester chacun un outil de corpus pour effecuter des annotations morpho-syntaxiques liées aux titres et descriptions des articles. 

J'ai fini de redonner un script python **annotation_spacy.py** ainsi qu'un résultat intitulé **sortie.xml** dans ma branche **zxh-s9** nouvellement créée. Le contenu sorti est assez satisfaisant avec les tokenisations dedans. Le problème pour l'instant, c'est justement que le script est vraiment lourd qui nécéssaite de se réorganiser à l'aide des plusieures fonctions possibles. Je décide de le faire après. 

## 8 avril 2023
**HUANG** : Après une séance consacrée à la correction du script pour les différentes sorties et à une courte introduction des analyseurs syntaxiques, il me reste quelques tâches à compléter avant d'entamer les analyses syntaxiques.

Tout d'abord, en basant sur les scripts du prof (extraction et datastructures), j'ai fait des ajouts au début des scripts sortie (export_xml.py et export_json.py) pour que la catégorie entrée puisse également être affiché dans les fichiers sorties (`json` et `xml`). L'affichage de `pickle` nous paraît difficile à analyser par humain, et nous l'avons donc abandonné comme sortie.

Après ces prétraitements de format, il est maintenant possible de procéder à l'analyse syntaxique. J'ai choisi cette fois l'analyseur automatique *Stanza*, ce que j'ai testé un peu en ligne avec son demo.

La structure et la fonction de *Stanza* ressemblent beaucoup à celles de *Spacy*, qui demande tous dmabord la tokenization, puis les autres fonctions comme `lemma` et `upos`. Il est à noter que la grande différence au début, c'est que *Stanza* sépare le corpus tout d'abord en phrases, puis en tokens (words). Les fonctions `text, lemma et upos` coresspondent au contenu attendu : `forme, lemme et pos`.

Par rapport à mon camarade, les lignes de programmes sont ajoutées dans les scripts de sortie (`export_json.py` et `export_xml.py`). Puisque maintenant il m'est encore confus de chosir un des deux formats, j'ai fait respectivement des modifications dans les deux scripts, afin que la forme de sortie soit idéale et corresponde à celle de mon camarade :

    Pour la sortie xml :

    <corpus begin="2022-01-01" end="2022-01-02" categorie="sport">
        <content>
        <article>
            <title>
            Coupe de France de football : Bastia et Nancy créent la surprise
            </title>
            <description>
            Les deux clubs de Ligue 2 ont écarté respectivement Clermont et Rennes, deux clubs de Ligue 1. Brest et Montpellier ont dominé Bordeaux et Strasbourg. Nantes est également qualifié.
            </description>
            <categorie/>
            <analyse>
                <token forme="Coupe" lemma="coupe" pos="NOUN"/>
                ...
            </analyse>


    Pour la sortie json :

    {
    "categories": [
        "sport"
    ],
    "begin": "2022-01-01",
    "end": "2022-01-02",
    "chemin": "./Corpus/2022",
    "articles": [
        {
            "titre": "Coupe de France de football\u00a0: Bastia et Nancy cr\u00e9ent la surprise",
            "description": "Les deux clubs de Ligue 2 ont \u00e9cart\u00e9 respectivement Clermont et Rennes, deux clubs de Ligue 1. Brest et Montpellier ont domin\u00e9 Bordeaux et Strasbourg. Nantes est \u00e9galement qualifi\u00e9.",
            "analyse": {
                "tokens": [
                    {
                        "forme": "Coupe",
                        "lemma": "coupe",
                        "pos": "NOUN"
                    },
        ...
                ]
            }
        ]
    }


Les scripts complets se trouvent dans la branche **hyd-s9** (dont le contenu est les nouvelles de la catégorie *sport* en 2022-01-01), les noms de ces fichiers sont `corpus.json`et `corpus.xml`.

Mais le script ne peut que prendre une catégorie en tant que source entrée, ce qui demanderait une amélioration pour faciliter l'analyse multidimensionelle ultérieure.



