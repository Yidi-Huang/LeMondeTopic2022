#Séance 11

## 24 avril 2023
**ZHANG**: Nos scripts pour les dernières déamrches ont été bien organisés et fusionnés dans la branche **main**. À l'aide de toutes les informations fournies dans la séance cette semaine, j'ai ainsi travaillé sur la modélisation de sujets avec `Genism` et `LDA`.

Après avoir installé le module `Gensim`, j'ai rencontré un erreur d'incompatibilité entre les modules Python lors de l'importation du module.
```
Numpy.ndarray size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject

```

En créant et activant un environnement virtuel, j'ai résolu ce problème et importé `Gensim` sans accroc. On est alors tout prêt à explorer la modélisation des motifs. *Petit rappel*: `source myenv/bin/activate` pour activer e-env `deactivate` pour le désactiver.


De plus, j'ai établi un nouveau script `LDA_model.py` tout en créant plussieurs fonctions :
- **charge_xml()**,**charge_json()**,**charge_pickle()**  pour faciliter l'importation de différents types de fichiers et les convertir en listes des documents
- une fonction spécifique **preprocess_documents(docs)** pour pré-entraîner les testes à être utilisés dans la modélisation de sujets
- **train_lda_model()** pour construire notre modèle LDA, un ensemble de paramètres a été mis en place dedans pour guider notre modèle d'entraînement. Une fois le modèle entraîné, nous avons calculé la cohérence moyenne des sujets, un indicateur clé de la qualité de notre modèle.
- pour couronner le tout, une fonction **visualize_lda_model()**pour visualiser les résultats de notre modèle LDA à l'aide de pyLDAvis.

## 25 avril 2023
**HUANG** : Les scripts pour le prétraitement de corpus sont tous bien formés. Notamment pour le script de l'analyseur `Stanza`, j'ai découvert qu'il est pas nécessaire de rappeler chaque fois *download* pour le pakage fr. Le script est testé en produisant un xml de sous-corpus et il en sorte que le résultat correspond bien au format pareil que `Spacy`.

En récupérant le script de la version du prof, j'ai obtenu un fichier html qui est capable d'analyser et de présenter les résultats obtenu par l'entraîenement de `LDA`. 

Le fichier *sortie.html* montre à droite les mots (ou je dirais plutôt les segments?) fréquents, mais les premiers rangs sont occupés par les ponctuation telles que *«*, ce qui me pose la question : faut-il créer d'autres fonctions pour ignorer et supprimer ces `mots vides` pour faciliter l'analyse sur les mots vrais (porte du sens) ?

Mon camarade a proposé un entraînement plus complet pour l'analyse, en comparant les deux sorties html, il me semble que ce serait intéressant de voir les fonctions précises et les différences.



